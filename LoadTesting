- POC tests: Pending application implementations
- POC priority: Complex tests (approx. 2 per application)
- Implementation approach: Each test done both with and without GitHub Copilot
For this application, we will execute a series of frontend automated scenarios. To develop these scenarios, we will utilize the Selenium test framework, renowned for its capacity to execute automated test cases in web browsers. In conjunction with Selenium, we will employ Java as our programming language and Intellij as our integrated development environment (IDE).
The extended proof-of-concept will be conducted by the quality management team, specifically involving three testers. Oversight of this initiative within the quality management department will be led by John Green. Additionally, the deployment of GitHub Copilot licenses within our company infrastructure will be overseen by John Scott, as previously arranged. Throughout the proof-of-concept phase, our objectives include implementing a comprehensive suite of tests for two designated applications.

The process comprises two distinct sub-processes: the development process and the test automation process.

Within the development process, software developers craft code, which is then committed to the production code repository, such as Bitbucket in our case. Subsequently, the code undergoes packaging and deployment into testing environments, allowing testers to verify its functionality. The deployed application provides an interface, such as a web interface or REST API, facilitating testing by the testers. Upon successful completion of testing, the code is deployed to production.

The test automation process involves two phases: the conceptual phase and the implementation phase. During the conceptual phase, testers analyze requirements, design test cases, and define expected outcomes. Once test cases are defined, the implementation phase commences, wherein automation testers select test scenarios and utilize automation frameworks like Selenium or RestAssured to develop automation scripts. These scripts are stored in a dedicated testing code repository within Bitbucket. Testers primarily use Java and IntelliJ IDE. Once automated, the test cases are deployed to Jenkins, our CI/CD solution. Jenkins initiates the automated test cases, executing various actions within the application deployed in a testing environment. Following each execution, Jenkins generates reports detailing the number of test scenarios that passed and failed, which are then presented to stakeholders.

The integration between the code developed by developers and the test automation process occurs solely during the execution of automated test suites by Jenkins. In our extended proof-of-concept, we aim to explore how GitHub Copilot can enhance the efficiency of test automation implementation, along with its broader benefits, across two selected applications.
The image depicts a comprehensive software development and testing process that integrates GitHub Copilot. Here's a manager-friendly summary:

1. **Code Commitment**: It starts with developers committing code to the production code repository.
2. **Test Deployment**: This code is then deployed to a test environment.
3. **Testing Phase**: In the test region, the application under test is subjected to testing.
4. **Copilot Assistance**: GitHub Copilot aids in implementing tests within the Test Automation Framework.
5. **Testing Tools**: Tools like Java, Selenium, and JUnit 5 are utilized for testing.
6. **Results Commitment**: The outcomes of these tests are committed to the Testing Code Repository.
7. **Final Deployment**: Jenkins is used to deploy the tested code.

This process ensures that the code is thoroughly tested and validated before being deployed, which aligns with best practices for software development and deployment.

Source: Conversation with Bing, 08/03/2024
(1) https://discuss.zerotier.com/t/how-to-get-access-from-windows-to-enigma2-openwebif.... https://discuss.zerotier.com/t/how-to-get-access-from-windows-to-enigma2-openwebif-enigma2/15107.
(2) https://www.youtube.com/watch?v=Udtr1zJhcrw. https://www.youtube.com/watch?v=Udtr1zJhcrw.
(3) https://www.flickr.com/photos/syvanen/6427667261. https://www.flickr.com/photos/syvanen/6427667261/.
(4) https://github.com/uyuni-project/uyuni/issues/1277. https://github.com/uyuni-project/uyuni/issues/1277.
(5) https://github.com/mszcool/cf-scp-on-azure-simple. https://github.com/mszcool/cf-scp-on-azure-simple.

Subject: Reminder: Data Cleaning for QMA Drive

Hello,

This is a friendly reminder regarding the data cleaning of our QMA drive, as per the previous email sent out. We kindly request all concerned members to move the necessary folders into the designated retention zone:

aaaaa\QMA\QM_Retention_Zone

The deadline to move your files is the end of next week. Any data/folder not moved will be subject to deletion within the following week.

If there are any queries or concerns, please feel free to reach out to us.

Thank you for your cooperation.

Best regards, [Your Name]Subject: Request to Add "Known Error" Resolution in JIRA

Dear [User],

Thank you for reaching out to us regarding the addition of a new resolution value, "Known Error," in JIRA. We appreciate your suggestion and understand the potential benefits it may bring to our workflow.

After careful consideration, we have decided not to proceed with adding "Known Error" as a resolution option in JIRA. Allow us to explain our reasoning behind this decision:

1. Resolution Clarity: The resolution field in JIRA is intended to capture the final state of an issue, indicating whether it has been resolved, rejected, or otherwise concluded. Introducing a "Known Error" resolution could blur the distinction between resolved issues and those still requiring action.

2. Workflow Integrity: We believe that maintaining a clear distinction between resolved and unresolved issues is essential for effective project management. Setting the resolution should typically occur when an issue is considered resolved or rejected, rather than when it is known to be a recurring problem or a known error.

3. Alternative Approach: If you encounter an issue that is a known error or requires further investigation but does not warrant immediate resolution, we recommend utilizing other fields or features within JIRA to manage this information. For example, you can use labels, comments, or link the issue to a relevant ticket for further investigation or tracking.

We understand that your intention is to maintain transparency and track known issues effectively. However, we believe that adhering to the established resolution process in JIRA will help ensure consistency and clarity across our projects.

If you have any further questions or concerns, please feel free to discuss them with us. We are always open to feedback and suggestions for improving our workflows.

Thank you for your understanding and cooperation.

Best regards,

[Your Name]
[Your Position/Role]
[Your Contact Information]

We will provide an update once the new enhancement has been implemented.

Regarding the second part of your email, we have also been addressing the issues related to notifications generated by certain tasks, which is why you may have received duplicate emails. However, the specific scenario you mentioned occurred yesterday. Initially, Lester was assigned to the ticket in question. Subsequently, upon receiving the first email notification, he removed himself as the assignee. Therefore, when the second email was sent, the assignee field was left empty, resulting in the primary recipient being directed to Jira support. In similar cases, it appears prudent to direct such notifications to the Data Protection team. Should you have any further inquiries, please do not hesitate to reach out.Achieving proficiency in GitHub Copilot entails mastering the art of crafting precise and accurate prompts. Writing prompts correctly ensures that Copilot generates code effectively and accurately. However, attaining mastery in prompt formulation is a skill that requires time and practice to develop

We experimented with several test automation scenarios, utilizing various frameworks and libraries to assess Copilot's support for implementing automated tests.
Copilot seamlessly integrates with popular test frameworks like JUnit, TestNG, SerenityBDD/Cucumber/JBehave, Selenium, and wc3270 for mainframe systems, used in BBH.
By providing a well-crafted prompt in a comment, Copilot can generate almost the entire test code for specific methods.
Subsequently, these methods require minimal or no modifications to align with our testing needs. The generated code adheres to proper naming conventions, formatting styles, and error handling techniques.
Additionally, by specifying keywords such as "assert," "verify," or "check," we can communicate the desired type of assertion for our tests. With proper prompts, you can generate even tests for boundary/edge cases.
I successfully generated a list of Maven dependencies in the pom.xml file and standard Selenium template code. Overall, I estimate that I saved approximately one to two hours on boilerplate code preparation over the past three days. This time-saving benefit could be even more significant for junior or regular test automation experts.

Slide 1: Integration with Popular Test FrameworksGitHub Copilot integrates seamlessly with popular test frameworks like JUnit, TestNG, SerenityBDD/Cucumber/JBehave, Selenium, and wc3270 for mainframe systems.This compatibility allows us to leverage existing frameworks and libraries, reducing the learning curve and enabling faster test implementation.For example, by providing a well-crafted prompt in a comment, Copilot can generate almost the entire test code for specific methods, which then require minimal or no modifications to align with our testing needs.Slide 2: Code Quality and EfficiencyThe code generated by Copilot adheres to proper naming conventions, formatting styles, and error handling techniques, ensuring high-quality code.By specifying keywords such as “assert,” “verify,” or “check,” we can communicate the desired type of assertion for our tests. With proper prompts, Copilot can even generate tests for boundary/edge cases.This leads to more robust and comprehensive test coverage, improving the reliability of our software.Slide 3: Time Savings and ProductivityOver the past three days, using Copilot for tasks like generating a list of Maven dependencies in the pom.xml file and standard Selenium template code saved approximately one to two hours on boilerplate code preparation.This time-saving benefit could be even more significant for junior or regular test automation experts, potentially saving hundreds of hours over the course of a project.These time savings translate directly into cost savings and increased productivity for the company.
 Sure, let’s consider a simple test scenario where we are testing a login functionality of a web application using Selenium WebDriver and TestNG in Java.Here’s a basic test case without using GitHub Copilot:import org.openqa.selenium.By;import org.openqa.selenium.WebDriver;import org.openqa.selenium.WebElement;import org.openqa.selenium.chrome.ChromeDriver;import org.testng.Assert;import org.testng.annotations.AfterMethod;import org.testng.annotations.BeforeMethod;import org.testng.annotations.Test;public class LoginTest { WebDriver driver; @BeforeMethod public void setup() { System.setProperty("webdriver.chrome.driver", "path_to_chromedriver"); driver = new ChromeDriver(); driver.get("https://www.example.com/login"); } @Test public void testLogin() { WebElement usernameField = driver.findElement(By.id("username")); WebElement passwordField = driver.findElement(By.id("password")); WebElement loginButton = driver.findElement(By.id("login")); usernameField.sendKeys("testuser"); passwordField.sendKeys("testpassword"); loginButton.click(); Assert.assertEquals(driver.getCurrentUrl(), "https://www.example.com/home"); } @AfterMethod public void teardown() { driver.quit(); }}Now, let’s see how much time we could save with GitHub Copilot:Writing the test method (5-10 minutes): With a well-crafted prompt, Copilot can generate the entire test method, including finding the web elements, performing actions on them, and asserting the expected outcome.Setting up and tearing down the test (5 minutes): Copilot can generate the @BeforeMethod and @AfterMethod annotations and their corresponding methods, saving time on setting up and tearing down the test.Error handling (5-10 minutes): Copilot can generate code for proper error handling techniques, saving time on thinking about and implementing these scenarios.Code formatting and conventions (5 minutes): The code generated by Copilot adheres to proper naming conventions and formatting styles, saving time on code reviews and refactoring.In total, for this simple test scenario, we could save approximately 20 to 30 minutes with GitHub Copilot. For more complex scenarios or for less experienced developers, the time savings could be even greater. Please note that these are rough estimates and actual time savings may vary.
 Sure, let’s consider a simple test scenario where we are testing a login functionality of a web application using Cucumber or Serenity BDD.Here’s a basic test case without using GitHub Copilot:Feature: Login Feature Scenario: Successful Login with Valid Credentials Given User is on Home Page When User Navigate to LogIn Page And User enters UserName and Password Then Message displayed Login Successfullypublic class Steps { @Given("^User is on Home Page$") public void user_is_on_Home_Page() { // code to navigate to home page } @When("^User Navigate to LogIn Page$") public void user_Navigate_to_LogIn_Page() { // code to navigate to login page } @When("^User enters UserName and Password$") public void user_enters_UserName_and_Password() { // code to enter username and password } @Then("^Message displayed Login Successfully$") public void message_displayed_Login_Successfully() { // code to check login success message }}Now, let’s see how much time we could save with GitHub Copilot:Writing the feature file (5-10 minutes): With a well-crafted prompt, Copilot can generate the entire feature file, including defining the scenario and the steps.Writing the step definitions (10-20 minutes): Copilot can generate the step definitions in Java, including the methods and the annotations.Error handling (5-10 minutes): Copilot can generate code for proper error handling techniques, saving time on thinking about and implementing these scenarios.Code formatting and conventions (5 minutes): The code generated by Copilot adheres to proper naming conventions and formatting styles, saving time on code reviews and refactoring.In total, for this simple test scenario, we could save approximately 25 to 45 minutes with GitHub Copilot. For more complex scenarios or for less experienced developers, the time savings could be even greater. Please note that these are rough estimates and actual time savings may vary


Writing the test method (10-20 minutes): With a well-crafted prompt, Copilot can generate the entire test method, including finding the form elements, entering border and edge case values, submitting the form, and checking the form submission result.
Setting up and tearing down the test (5 minutes): Copilot can generate the @BeforeMethod and @AfterMethod annotations and their corresponding methods, saving time on setting up and tearing down the test.
Error handling (5-10 minutes): Copilot can generate code for proper error handling techniques, saving time on thinking about and implementing these scenarios.
Code formatting and conventions (5 minutes): The code generated by Copilot adheres to proper naming conventions and formatting styles, saving time on code reviews and refactoring.


Code Generation: GitHub Copilot can generate code for specific methods, classes, or functions based on the description provided. This reduces the time spent on writing boilerplate code.
Test Case Generation: With a well-crafted prompt, Copilot can generate test cases for your methods, including edge cases. This saves time on thinking through and writing each individual test case.
Integration with Testing Libraries: Copilot integrates with popular testing libraries in both Java (like JUnit, TestNG) and Python (like unittest, pytest). It can generate code that uses these libraries, saving time on looking up syntax and usage.
Code Quality: The code generated by Copilot adheres to good coding practices, including proper naming conventions and error handling. This reduces the time spent on code reviews and debugging.
Learning New Libraries/APIs: If you’re using a new library or API, Copilot can provide code suggestions based on its usage. This can save time on reading documentation or searching for examples online.
Automation: For repetitive tasks or patterns, Copilot can generate the necessary code, reducing the time spent on manual coding.
